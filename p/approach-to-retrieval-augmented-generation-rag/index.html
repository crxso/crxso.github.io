<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Vector Databases and Nomic Embed"><title>Approach to Retrieval-Augmented Generation (RAG)</title><link rel=canonical href=https://crxso.github.io/p/approach-to-retrieval-augmented-generation-rag/><link rel=stylesheet href=/scss/style.min.389ec2e2031e61386474ebd4c8e5f080c8180a38baa6ee2ee16a610692d8d5e3.css><meta property='og:title' content="Approach to Retrieval-Augmented Generation (RAG)"><meta property='og:description' content="Vector Databases and Nomic Embed"><meta property='og:url' content='https://crxso.github.io/p/approach-to-retrieval-augmented-generation-rag/'><meta property='og:site_name' content='@crxso'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Informational'><meta property='article:published_time' content='2025-10-03T21:41:29-07:00'><meta property='article:modified_time' content='2025-10-03T00:00:00+00:00'><meta property='og:image' content='https://crxso.github.io/p/approach-to-retrieval-augmented-generation-rag/balrog.jpg'><meta name=twitter:title content="Approach to Retrieval-Augmented Generation (RAG)"><meta name=twitter:description content="Vector Databases and Nomic Embed"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://crxso.github.io/p/approach-to-retrieval-augmented-generation-rag/balrog.jpg'><link rel="shortcut icon" href=/favicon.png><style>.fixed-datetime-header{position:fixed!important;top:0!important;z-index:1000!important;background-color:var(--header-background)!important;border-bottom:1px solid var(--header-border-color)!important;color:var(--header-text-color)!important;border-radius:0 0 4px 4px;height:33px;box-sizing:border-box;left:0!important;right:0!important;width:100%!important;padding:10px 15px!important;display:flex!important;align-items:center!important;justify-content:center!important}.article-page #main{padding-top:55px!important;margin-top:0!important}body:not(.article-page) #main{padding-top:0!important;margin-top:0!important}body:not(.article-page) .custom-homepage-content{margin-top:-80px!important;padding-top:125px!important;padding-bottom:0!important;margin-bottom:0!important}@media(min-width:1025px){.fixed-datetime-header{width:auto!important;left:50%!important;transform:translateX(-50%);right:auto!important;border-radius:0 0 4px 4px;border-bottom:1px solid var(--header-border-color)!important;box-shadow:0 4px 6px rgba(0,0,0,.1);padding:8px 25px!important}}@media(min-width:900px) and (max-width:1024px){.fixed-datetime-header{width:auto!important;left:50%!important;transform:translateX(-50%);right:auto!important;border-radius:0 0 4px 4px;border-bottom:1px solid var(--header-border-color)!important;box-shadow:0 4px 6px rgba(0,0,0,.1);padding:8px 25px!important}#main{padding-top:55px!important;margin-top:0!important}}@media(max-width:899px){.fixed-datetime-header{left:0!important;right:0!important;width:100%!important;border-bottom:1px solid var(--header-border-color)!important;box-shadow:none;padding:10px 15px!important}}</style><div class=fixed-datetime-header><div id=live-time-display-container style=display:flex;justify-content:center;align-items:center;font-size:1.1em;width:auto><div id=live-time-date-wrapper style=display:flex;align-items:center;margin-right:40px><svg style="width:1.2em;height:1.2em;fill:currentColor;margin-right:5px" viewBox="0 0 24 24"><path d="M19 4h-1V2h-2v2H8V2H6v2H5c-1.11.0-1.99.9-1.99 2L3 20c0 1.1.89 2 2 2h14c1.1.0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 16H5V9h14v11zM5 7V6h14v1H5z"/></svg>
<time id=live-time-date></time></div><div id=live-time-time-wrapper style=display:flex;align-items:center><svg style="width:1.2em;height:1.2em;fill:currentColor;margin-right:5px" viewBox="0 0 24 24"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm.5 16H11V7h1.5v4.75l3.43 3.05-.94 1.48L12.5 13.5V18z"/></svg>
<time id=live-time-time></time></div></div></div><script>function updateLiveTime(){const e=document.querySelector(".fixed-datetime-header");if(!e)return;const n=e.querySelector("#live-time-date"),s=e.querySelector("#live-time-time");if(!n||!s)return;const o=new Date,i={weekday:"short",month:"short",day:"numeric",year:"numeric"},a=o.toLocaleDateString("en-US",i).replace(/,/g,""),r={hour:"numeric",minute:"2-digit",second:"2-digit",hour12:!0,timeZoneName:"short"},t=o.toLocaleTimeString("en-US",r).split(" "),c=t.slice(0,2).join(" "),l=t.length>2?t.pop():"";n.textContent=a,s.textContent=`${c} ${l}`}updateLiveTime(),setInterval(updateLiveTime,1e3)</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/desk_hu_e63a407afe0a777a.png width=300 height=319 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>@crxso</a></h1><h2 class=site-description></h2></div></header><ol class=menu-social><li><a href=https://github.com/crxso target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#rag-structure>RAG Structure</a><ol><li><a href=#workflow-diagram>Workflow Diagram</a></li></ol></li><li><a href=#rag-workflow-diagram-explanation>RAG Workflow Diagram Explanation</a><ol><li><a href=#phase-1-indexing-pipeline-pre-processing>Phase 1: Indexing Pipeline (Pre-Processing)</a></li><li><a href=#phase-2-retrieval-pipeline-query-time>Phase 2: Retrieval Pipeline (Query Time)</a></li></ol></li><li><a href=#benefits-to-utilizing-vector-databases>Benefits to Utilizing Vector Databases</a><ol><li><a href=#the-indexing-problem-vector-databases-vs-csv>The Indexing Problem: Vector Databases vs. CSV</a><ol><li><a href=#python-example>Python Example</a></li><li><a href=#comparison-table>Comparison Table</a></li></ol></li><li><a href=#the-role-of-embedding-models-nomic-embed>The Role of Embedding Models: Nomic Embed</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/approach-to-retrieval-augmented-generation-rag/><img src=/p/approach-to-retrieval-augmented-generation-rag/balrog_hu_dfe8c105d16ca85b.jpg srcset="/p/approach-to-retrieval-augmented-generation-rag/balrog_hu_dfe8c105d16ca85b.jpg 800w, /p/approach-to-retrieval-augmented-generation-rag/balrog_hu_f34c45b2f1707359.jpg 1600w" width=800 height=450 loading=lazy alt="Featured image of post Approach to Retrieval-Augmented Generation (RAG)"></a></div><div class=article-details><header class=article-category><a href=/categories/ai/ style=background-color:#e02424;color:#fff>AI
</a><a href=/categories/rag/ style=background-color:#0177b8;color:#fff>RAG</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/approach-to-retrieval-augmented-generation-rag/>Approach to Retrieval-Augmented Generation (RAG)</a></h2><h3 class=article-subtitle>Vector Databases and Nomic Embed</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Fri Oct 3, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>7 minute read</time></div></footer></div></header><section class=article-content><div class=table-wrapper><table><thead><tr><th style=text-align:left>Version</th><th style=text-align:left>Updated on</th><th style=text-align:left>Updated by</th></tr></thead><tbody><tr><td style=text-align:left>v1.0.0</td><td style=text-align:left>10/03/2025</td><td style=text-align:left>@crxso</td></tr></tbody></table></div><h2 id=rag-structure>RAG Structure</h2><p><strong>Retrieval-Augmented Generation (RAG)</strong> is a technique that uses Large Language Models (LLMs) with external, proprietary knowledge to improve accuracy and reduce &ldquo;<strong>hallucination</strong>&rdquo;. The success of any RAG system relies entirely on its ability to quickly and accurately retrieve relevant context from a knowledge base.</p><ul><li><strong>Hallucination</strong> is a phenomenon where the LLM generates a response that is plausible-sounding and fluent but is factually incorrect, nonsensical, or unfaithful to the source information.</li></ul><p>This analysis focuses on the preferred, <strong>structured approach</strong> for RAG, which utilizes a dedicated <strong>vector database</strong> (like ChromaDB) and a specialized <strong>embedding model</strong> (i.e., Nomic Embed), as opposed to simple file storage methods like CSVs.</p><hr><h3 id=workflow-diagram>Workflow Diagram</h3><p><img src=/p/approach-to-retrieval-augmented-generation-rag/rag_flow.jpg width=1024 height=857 srcset="/p/approach-to-retrieval-augmented-generation-rag/rag_flow_hu_3660170bf900462c.jpg 480w, /p/approach-to-retrieval-augmented-generation-rag/rag_flow_hu_23bc3d064b0d975f.jpg 1024w" loading=lazy alt="RAG Flow" class=gallery-image data-flex-grow=119 data-flex-basis=286px></p><hr><h2 id=rag-workflow-diagram-explanation>RAG Workflow Diagram Explanation</h2><p>The RAG workflow is divided into two distinct, interconnected phases: the <strong>Indexing Pipeline</strong> (done offline or periodically) and the <strong>Retrieval & Generation Pipeline</strong> (done live every time a user asks a question).</p><h3 id=phase-1-indexing-pipeline-pre-processing>Phase 1: Indexing Pipeline (Pre-Processing)</h3><p>This phase builds the searchable knowledge base, which is the alternative to using a simple CSV file.</p><ol><li><p><strong>Raw Documents:</strong> Your source data, such as PDFs, text files, or data extracted from CSVs.</p><ul><li><strong>Role of Specified Tool:</strong> This is the proprietary data that the Large Language Model (LLM) was not trained on.</li></ul></li><li><p><strong>Chunking:</strong> The process of splitting large documents into smaller, manageable text sections (chunks).</p><ul><li><strong>Purpose:</strong> LLMs and vector search operate better on smaller, contextually coherent blocks of text, as very long documents exceed the model&rsquo;s token limits and introduce irrelevant noise.</li></ul></li><li><p><strong>Nomic Embed (Vectorization):</strong> Each text chunk is passed through the Nomic Embed model, which converts the text&rsquo;s semantic meaning into a dense numerical array (<strong>a vector</strong>).</p><ul><li><strong>Tool:</strong> The Nomic Embed model is the Embedding Model. It creates high-quality vectors that enable semantic search.</li></ul></li><li><p><strong>ChromaDB (Vector Store):</strong> The resulting vector and its corresponding original text chunk are stored here.</p><ul><li><strong>Tool:</strong> ChromaDB is the Vector Store. It is optimized to index, store, and manage these vectors, building a fast index that makes the vectors easily searchable by mathematical similarity.</li></ul></li><li><p><strong>Vectors:</strong> The resulting high-dimensional numerical data points ready for search.</p><ul><li><strong>Role of Specified Tool:</strong> This is the final, structured representation of your knowledge base, which is infinitely more useful than raw text in a CSV for RAG.</li></ul></li></ol><h3 id=phase-2-retrieval-pipeline-query-time>Phase 2: Retrieval Pipeline (Query Time)</h3><p>This phase happens in real-time and is the core of the RAG process.</p><ol><li><p><strong>User Query:</strong> The natural language question asked by the end-user (e.g., &ldquo;What is the policy on annual leave?&rdquo;).</p></li><li><p><strong>Nomic Embed (Vectorization):</strong> The user&rsquo;s query is passed through the <em>exact same</em> Nomic Embed model used in the Indexing Phase. This ensures the query is mapped to the same <strong>semantic vector space</strong> as the stored documents, allowing for accurate comparison.</p></li><li><p><strong>ChromaDB (Vector Store) / Search/KNN:</strong> The resulting <strong>Query Vector</strong> is sent to ChromaDB, which performs a <strong>K-Nearest Neighbors (KNN)</strong> search to find the vectors that are mathematically closest to the Query Vector.</p></li><li><p><strong>Retrieval / Top N Context Chunks:</strong> The original text chunks associated with those closest vectors are retrieved (e.g., the top 3 paragraphs about the &ldquo;annual leave policy&rdquo;). This is the relevant, factually grounded context pulled from your knowledge base.</p></li><li><p><strong>LLM Prompt (Augmented Prompt):</strong> The retrieved text chunks are combined with the original User Query into a single, cohesive message template.</p><ul><li><strong>Template Example:</strong> &ldquo;Use the following context to answer the question: [Top N Context Chunks]. Question: [User Query].&rdquo;*</li></ul></li><li><p><strong>Final Answer (Generation):</strong> The complete augmented prompt is passed to the LLM (the Generative Model). The LLM uses the provided facts (the context) to formulate a coherent, factually grounded response, minimizing &ldquo;hallucination&rdquo; by relying on the context provided by ChromaDB.</p></li></ol><hr><h2 id=benefits-to-utilizing-vector-databases>Benefits to Utilizing Vector Databases</h2><h3 id=the-indexing-problem-vector-databases-vs-csv>The Indexing Problem: Vector Databases vs. CSV</h3><p>The fundamental difference between a CSV file and a vector database for RAG lies in the type of search they enable: <strong>Keyword Search versus Semantic Search</strong>. Using a vector store transforms your knowledge base from a simple storage file into an intelligent, searchable index capable of understanding intent.</p><blockquote><p>A vector database is a specialized type of database designed to store, manage, and retrieve vector embeddings; high-dimensional numerical representations of unstructured data like text, images, or audio.</p><p>It enables highly efficient and fast semantic search by measuring the distance (or similarity) between two vectors, allowing applications to retrieve data based on meaning or context rather than exact keyword matches.</p></blockquote><p>Using a vector store like ChromaDB transforms your knowledge base from a simple storage file into an intelligent, searchable index capable of understanding intent, which is beneficial for RAG outputs.</p><h4 id=python-example>Python Example</h4><ul><li>This python code sets up a Retrieval-Augmented Generation (RAG) system by using the Nomic Embed model to convert data from a local CSV file into numerical vectors, which are then stored in a ChromaDB vector store.</li><li>The code initializes a PandasAI SmartDataframe with an Ollama LLM and the ChromaDB vector store, allowing the user to query the DataFrame and retrieve contextually grounded answers from the indexed CSV data.</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=ch>#!/usr/bin/env python3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pandasai</span> <span class=kn>import</span> <span class=n>SmartDataframe</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_ollama</span> <span class=kn>import</span> <span class=n>OllamaLLM</span><span class=p>,</span> <span class=n>OllamaEmbeddings</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_community.vectorstores</span> <span class=kn>import</span> <span class=n>Chroma</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.schema</span> <span class=kn>import</span> <span class=n>Document</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. CONFIGURATION</span>
</span></span><span class=line><span class=cl><span class=n>LLM_MODEL</span> <span class=o>=</span> <span class=s2>&#34;qwen2.5-coder:7b&#34;</span>
</span></span><span class=line><span class=cl><span class=n>EMBEDDING_MODEL</span> <span class=o>=</span> <span class=s2>&#34;nomic-embed-text&#34;</span>
</span></span><span class=line><span class=cl><span class=n>CSV_PATH</span> <span class=o>=</span> <span class=s2>&#34;CSV_PATH has been removed for security/privacy&#34;</span>
</span></span><span class=line><span class=cl><span class=n>CHROMA_PATH</span> <span class=o>=</span> <span class=s2>&#34;./chroma_db&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. INITIALIZE COMPONENTS</span>
</span></span><span class=line><span class=cl><span class=c1># Ollama models are assumed to be running via &#39;ollama serve&#39;</span>
</span></span><span class=line><span class=cl><span class=n>ollama_llm</span> <span class=o>=</span> <span class=n>OllamaLLM</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=n>LLM_MODEL</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ollama_embeddings</span> <span class=o>=</span> <span class=n>OllamaEmbeddings</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=n>EMBEDDING_MODEL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. LOAD &amp; PREPARE DATA</span>
</span></span><span class=line><span class=cl><span class=c1># NOTE: Assuming &#39;df&#39; is loaded from CSV_PATH here for demonstration</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&#34;your_data.csv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Convert DataFrame rows into LangChain Documents</span>
</span></span><span class=line><span class=cl><span class=n>documents</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Combine all values into a single string for embedding</span>
</span></span><span class=line><span class=cl>    <span class=n>content</span> <span class=o>=</span> <span class=s2>&#34;, &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>col</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>val</span><span class=si>}</span><span class=s2>&#34;</span> <span class=k>for</span> <span class=n>col</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=n>row</span><span class=o>.</span><span class=n>items</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>    <span class=c1># Optional: Add metadata</span>
</span></span><span class=line><span class=cl>    <span class=n>metadata</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;row_index&#34;</span><span class=p>:</span> <span class=n>index</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Document</span><span class=p>(</span><span class=n>page_content</span><span class=o>=</span><span class=n>content</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=n>metadata</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. CREATE/LOAD CHROMA VECTOR STORE</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Indexing data into ChromaDB... (This may take a moment the first time)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>vectorstore</span> <span class=o>=</span> <span class=n>Chroma</span><span class=o>.</span><span class=n>from_documents</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span><span class=o>=</span><span class=n>documents</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>embedding</span><span class=o>=</span><span class=n>ollama_embeddings</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>persist_directory</span><span class=o>=</span><span class=n>CHROMA_PATH</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;ChromaDB Indexing Complete.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. INTERACT WITH SMARTDATAFRAME USING THE VECTOR STORE</span>
</span></span><span class=line><span class=cl><span class=c1># The &#39;vector_store&#39; config enables RAG for complex, non-data-manipulation queries.</span>
</span></span><span class=line><span class=cl><span class=n>sdf</span> <span class=o>=</span> <span class=n>SmartDataframe</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;llm&#34;</span><span class=p>:</span> <span class=n>ollama_llm</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;vector_store&#34;</span><span class=p>:</span> <span class=n>vectorstore</span><span class=p>,</span> <span class=c1># Pass the initialized vector store here</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;enable_code_execution&#34;</span><span class=p>:</span> <span class=kc>True</span> <span class=c1># Essential for PandasAI to run generated code</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Example 1: A general, non-data query (uses Vector Store/RAG)</span>
</span></span><span class=line><span class=cl><span class=n>rag_query</span> <span class=o>=</span> <span class=s2>&#34;Summarize the types of service images mentioned in the dataset.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>response_rag</span> <span class=o>=</span> <span class=n>sdf</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>rag_query</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>--- RAG Query Response (Vector Store):</span><span class=se>\n</span><span class=si>{</span><span class=n>response_rag</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Example 2: A data analysis query (uses DataFrame/Code Generation)</span>
</span></span><span class=line><span class=cl><span class=n>analysis_query</span> <span class=o>=</span> <span class=s2>&#34;What is the average value of the &#39;impact_score&#39; column?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>response_analysis</span> <span class=o>=</span> <span class=n>sdf</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>analysis_query</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>--- Analysis Query Response (DataFrame):</span><span class=se>\n</span><span class=si>{</span><span class=n>response_analysis</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># The original query</span>
</span></span><span class=line><span class=cl><span class=c1># Since the query contains the specific text you indexed, the vector store can retrieve the document containing that text and the LLM can extract the version.</span>
</span></span><span class=line><span class=cl><span class=n>vector_query</span> <span class=o>=</span> <span class=s2>&#34;what is the version of this service image: [service_image]&#34;</span>
</span></span><span class=line><span class=cl><span class=n>response_vector</span> <span class=o>=</span> <span class=n>sdf</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>vector_query</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>--- Specific Vector Query Response:</span><span class=se>\n</span><span class=si>{</span><span class=n>response_vector</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><hr><h4 id=comparison-table>Comparison Table</h4><div class=table-wrapper><table><thead><tr><th style=text-align:left>Feature</th><th style=text-align:left>CSV/Flat File Storage</th><th style=text-align:left>Vector Database (ChromaDB)</th></tr></thead><tbody><tr><td style=text-align:left><strong>Indexing Method</strong></td><td style=text-align:left>Keyword-based (e.g., full-text search) or simple relational index.</td><td style=text-align:left>High-dimensional vector indexing (e.g., HNSW) for fast Nearest Neighbor search.</td></tr><tr><td style=text-align:left><strong>Search Type</strong></td><td style=text-align:left><strong>Keyword Search:</strong> Requires exact word matches or close synonyms.</td><td style=text-align:left><strong>Semantic Search:</strong> Finds information based on meaning and context, even if the exact words are not present.</td></tr><tr><td style=text-align:left><strong>Scalability</strong></td><td style=text-align:left>Poor. Search time increases linearly with data size.</td><td style=text-align:left>Excellent. Optimized for querying billions of vectors efficiently and at low latency.</td></tr><tr><td style=text-align:left><strong>Relevance</strong></td><td style=text-align:left>Low precision. Cannot capture nuance, complex relationships, or abstract concepts.</td><td style=text-align:left>High precision. Captures semantic distance, ensuring the retrieved context is genuinely relevant to the query&rsquo;s intent.</td></tr></tbody></table></div><h3 id=the-role-of-embedding-models-nomic-embed>The Role of Embedding Models: Nomic Embed</h3><p>An embedding model&rsquo;s primary function is to transform raw text (your documents and the user&rsquo;s query) into <strong>numerical representations called vectors</strong>. <strong>Nomic Embed</strong> provides the translation layer that makes semantic search possible.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=c1># Command used to display currently downloaded models</span>
</span></span><span class=line><span class=cl><span class=n>Ollama</span> <span class=n>list</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nomic</span><span class=o>-</span><span class=n>embed</span><span class=o>-</span><span class=n>text</span><span class=p>:</span><span class=n>latest</span> <span class=mi>0</span><span class=n>a10XXXXXXXX</span> <span class=mi>274</span> <span class=n>MB</span> <span class=mi>7</span> <span class=n>days</span> <span class=n>ago</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><p><strong>High Fidelity:</strong> Nomic models are designed to be competitive with and often outperform existing proprietary models, capturing subtle semantic relationships and context.</p></li><li><p><strong>Long Context Window:</strong> They feature a long context length, which is best for RAG. A longer context window allows the model to embed larger chunks of text accurately, ensuring that vectors retain the full context of lengthy documents.</p></li><li><p><strong>Structured Advantage:</strong> Utilizing Nomic Embed guarantees that every piece of data indexed is represented in a uniform, high-dimensional space, which is what the vector database (ChromaDB) is optimized to search across. Without a powerful embedding model, the quality of the RAG output suffers significantly.</p></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/informational/>Informational</a></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Fri Oct 03, 2025</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/local-cve-exploitability-analyzer/><div class=article-image><img src=/p/local-cve-exploitability-analyzer/rivendell.25ea293e972680ff70776b4997e3ff97_hu_30ea1eff0f89afbe.jpg width=250 height=150 loading=lazy alt="Featured image of post Local CVE Exploitability Analyzer" data-hash="md5-JeopPpcmgP9wd2tJl+P/lw=="></div><div class=article-details><h2 class=article-title>Local CVE Exploitability Analyzer</h2></div></a></article><article class=has-image><a href=/p/local-ai-setup/><div class=article-image><img src=/p/local-ai-setup/ollama.17043ccc385d9e14cd4dd40474918aea_hu_fe83d579461207b5.png width=250 height=150 loading=lazy alt="Featured image of post Local AI Setup" data-hash="md5-FwQ8zDhdnhTNTdQEdJGK6g=="></div><div class=article-details><h2 class=article-title>Local AI Setup</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2024 -
2025 @crxso</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
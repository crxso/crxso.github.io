[{"content":" Version Updated on Updated by v1.0.0 10/09/2025 @crxso Project Goal The Local CVE Exploitability Analyzer project implements an automated system for assessing the exploitability of Common Vulnerabilities and Exposures (CVEs).\nThe core functionality is built upon a Retrieval-Augmented Generation (RAG) architecture using two local components:\nOllama for the Language Model (LLM) and embeddings ChromaDB for the vector store; emulating the multi-LLM agentic framework described in the project plan. The objective is to develop an automated system for assessing the exploitability of Common Vulnerabilities and Exposures (CVEs). The system uses a multi-LLM agentic framework to perform comprehensive analysis and provide a clear, actionable \u0026ldquo;proof of exploitability\u0026rdquo; score or narrative. The ultimate goal is to move beyond simple vulnerability detection to a proactive, threat-informed security posture.\nMethodology \u0026amp; Technical Approach The system leverages an agentic AI framework where multiple specialized LLMs (agents) work together under a central orchestration layer. This approach deconstructs the CVE analysis into specialized functions, minimizing the risk of hallucination and allowing for targeted fine-tuning and debugging.\nAgent Roles \u0026amp; Responsibilities (Implemented in run_system.py) The three conceptual agents are functionally implemented within the logic of run_system.py and the RAG chain\u0026rsquo;s prompt structure:\nData Retrieval Agent: Implemented by the fetch_and_save_cve function in run_system.py. It is responsible for retrieving all relevant CVE information from external sources like NVD and MITRE and gathering exploitation evidence from CISA KEV and Exploit-DB. The fetched data is saved locally and forms the LocalGPT RAG knowledge base.\nVulnerability Analysis Agent: The first stage of the run_rag_chain in run_system.py, where the LLM\u0026rsquo;s Chain of Thought (Steps 1-3) analyzes the data retrieved from the vector store to interpret the vulnerability\u0026rsquo;s nature, root cause, and potential impact.\nExploit Assessment Agent: The second stage of the run_rag_chain in run_system.py, where the LLM\u0026rsquo;s Chain of Thought (Steps 4-7) synthesizes the analysis, evaluates exploitability based on PoC code, and determines the final Verdict and Mitigations \u0026amp; Fixes.\nCore Program Descriptions The system consists of two main programs: the backend analysis engine (run_system.py) and the frontend web application (app.py).\nrun_system.py: The RAG Engine This Python script is the backend analysis engine and RAG implementation. It handles all data ingestion, vector store management, and the final LLM-based analysis.\nFunction Description Conceptual Agent Role clear_data_directory Clears the previous run\u0026rsquo;s fetched data (cve_data) and the vector database (cve_database) to ensure a fresh, specific analysis. Orchestration Layer fetch_exploit_db_id Searches the Exploit-DB website to find associated exploit IDs for the target CVE. Data Retrieval Agent fetch_exploit_db_poc Fetches the raw Proof-of-Concept (PoC) code from Exploit-DB using the retrieved ID. Data Retrieval Agent fetch_and_save_cve Fetches vulnerability data from NVD, MITRE, and CISA KEV. It compiles this data, along with any Exploit-DB PoCs, into Markdown files and saves them to the cve_data directory. Data Retrieval Agent build_vector_store Initializes the ChromaDB client, loads the Markdown files from cve_data, chunks them using RecursiveCharacterTextSplitter, and embeds the chunks using OllamaEmbeddings (nomic-embed-text) to create the RAG knowledge base. Orchestration Layer / RAG Setup run_rag_chain This is the core analysis function. It sets up the RAG pipeline using LangChain: it retrieves relevant document chunks from the vector store and passes them, along with the Exploit-DB PoCs, to the Ollama LLM (mistral:instruct) with a detailed, structured prompt for generating the final analysis report. Analysis Agent \u0026amp; Exploit Assessment Agent 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 # run_system.py #!/usr/bin/env python3 import json import os import requests import chromadb from langchain_community.document_loaders import DirectoryLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain_community.vectorstores import Chroma from langchain_ollama import OllamaEmbeddings, OllamaLLM from langchain.prompts import PromptTemplate from langchain_core.runnables import RunnablePassthrough, RunnableLambda import argparse import shutil import time import traceback NVD_API_KEY = \u0026#34;redacted\u0026#34; DATA_DIR = \u0026#34;./cve_data\u0026#34; DB_PATH = \u0026#34;./cve_database\u0026#34; COLLECTION_NAME = \u0026#34;cve_collection\u0026#34; def clear_data_directory(logger=None): if os.path.exists(DATA_DIR): if logger: logger(f\u0026#34;Clearing contents of {DATA_DIR}...\u0026#34;) for filename in os.listdir(DATA_DIR): file_path = os.path.join(DATA_DIR, filename) try: if os.path.isfile(file_path) or os.path.islink(file_path): os.unlink(file_path) elif os.path.isdir(file_path): shutil.rmtree(file_path) except Exception as e: if logger: logger(f\u0026#34;Failed to delete {file_path}. Reason: {e}\u0026#34;) else: os.makedirs(DATA_DIR, exist_ok=True) if logger: logger(f\u0026#34;Created data directory: {DATA_DIR}\u0026#34;) if os.path.exists(DB_PATH): try: if logger: logger(f\u0026#34;Deleting database directory {DB_PATH}...\u0026#34;) shutil.rmtree(DB_PATH) if logger: logger(f\u0026#34;Successfully deleted {DB_PATH}\u0026#34;) except Exception as e: if logger: logger(f\u0026#34;Failed to delete database directory {DB_PATH}. Reason: {e}\u0026#34;) else: if logger: logger(f\u0026#34;Database directory {DB_PATH} does not exist, skipping deletion.\u0026#34;) def fetch_exploit_db_id(cve_id, logger=None): search_url = f\u0026#34;[https://www.exploit-db.com/search?cve=](https://www.exploit-db.com/search?cve=){cve_id}\u0026#34; headers = { \u0026#34;Accept\u0026#34;: \u0026#34;application/json, text/javascript, */*; q=0.01\u0026#34;, \u0026#34;X-Requested-With\u0026#34;: \u0026#34;XMLHttpRequest\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) \u0026#34; \u0026#34;AppleWebKit/537.36 (KHTML, like Gecko) \u0026#34; \u0026#34;Chrome/115.0.0.0 Safari/537.36\u0026#34;, \u0026#34;Referer\u0026#34;: \u0026#34;[https://www.exploit-db.com/](https://www.exploit-db.com/)\u0026#34;, } try: response = requests.get(search_url, headers=headers) response.raise_for_status() data = response.json() if data.get(\u0026#34;recordsTotal\u0026#34;, 0) \u0026gt; 0 and data.get(\u0026#34;data\u0026#34;): exploit_ids = [item[\u0026#34;id\u0026#34;] for item in data[\u0026#34;data\u0026#34;]] if logger: logger(f\u0026#34;Found Exploit-DB IDs {exploit_ids} for CVE {cve_id}\u0026#34;) return exploit_ids else: if logger: logger(f\u0026#34;No Exploit-DB entries found for CVE {cve_id}\u0026#34;) return [] except Exception as e: if logger: logger(f\u0026#34;Failed to fetch Exploit-DB ID: {e}\u0026#34;) return [] def fetch_exploit_db_poc(exploit_id, logger=None): raw_url = f\u0026#34;[https://www.exploit-db.com/raw/](https://www.exploit-db.com/raw/){exploit_id}\u0026#34; headers = { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) \u0026#34; \u0026#34;AppleWebKit/537.36 (KHTML, like Gecko) \u0026#34; \u0026#34;Chrome/115.0.0.0 Safari/537.36\u0026#34; } try: response = requests.get(raw_url, headers=headers) response.raise_for_status() if logger: logger(f\u0026#34;Successfully fetched Exploit-DB PoC for ID {exploit_id}\u0026#34;) return response.text except Exception as e: if logger: logger(f\u0026#34;Failed to fetch Exploit-DB PoC: {e}\u0026#34;) return None def fetch_and_save_cve(cve_id, nvd_api_key, logger=None): url = \u0026#34;[https://services.nvd.nist.gov/rest/json/cves/2.0](https://services.nvd.nist.gov/rest/json/cves/2.0)\u0026#34; params = {\u0026#34;cveId\u0026#34;: cve_id} headers = {\u0026#34;apiKey\u0026#34;: nvd_api_key} nvd_data = {} cve_info = None try: response = requests.get(url, headers=headers, params=params) response.raise_for_status() nvd_data = response.json() vulns = nvd_data.get(\u0026#34;vulnerabilities\u0026#34;, []) if not vulns: if logger: logger(f\u0026#34;No NVD data found for {cve_id}. Skipping.\u0026#34;) return False, [], [] cve_info = vulns[0].get(\u0026#34;cve\u0026#34;, {}) if logger: logger(f\u0026#34;Successfully retrieved NVD data for {cve_id}.\u0026#34;) except Exception as e: if logger: logger(f\u0026#34;Failed to fetch NVD data: {e}\u0026#34;) return False, [], [] cisa_kev_data = {} mitre_cve_data = {} try: mitre_url = f\u0026#34;[https://cveawg.mitre.org/api/cve/](https://cveawg.mitre.org/api/cve/){cve_id}\u0026#34; mitre_response = requests.get(mitre_url) mitre_response.raise_for_status() mitre_cve_data = mitre_response.json() if logger: logger(f\u0026#34;Successfully retrieved MITRE CVE data for {cve_id}.\u0026#34;) except Exception as e: if logger: logger(f\u0026#34;Failed to fetch MITRE CVE data: {e}\u0026#34;) try: cisa_url = \u0026#34;[https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json](https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json)\u0026#34; cisa_response = requests.get(cisa_url) cisa_response.raise_for_status() cisa_kev_feed = cisa_response.json() cisa_kev_data[\u0026#39;is_kev_exploited\u0026#39;] = any( item[\u0026#39;cveID\u0026#39;] == cve_id for item in cisa_kev_feed.get(\u0026#39;vulnerabilities\u0026#39;, []) ) if logger: logger(f\u0026#34;Successfully retrieved and searched CISA KEV data.\u0026#34;) except Exception as e: if logger: logger(f\u0026#34;Failed to fetch CISA KEV data: {e}\u0026#34;) cisa_kev_data[\u0026#39;is_kev_exploited\u0026#39;] = False exploit_db_ids = fetch_exploit_db_id(cve_id, logger=logger) exploit_db_pocs = [] for eid in exploit_db_ids: poc = fetch_exploit_db_poc(eid, logger=logger) if poc: exploit_db_pocs.append((eid, poc)) poc_filename = os.path.join(DATA_DIR, f\u0026#34;{cve_id}_exploit_{eid}.md\u0026#34;) with open(poc_filename, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(f\u0026#34;# Exploit DB PoC for {cve_id} - Exploit ID {eid}\\n\\n\u0026#34;) f.write(\u0026#34;```text\\n\u0026#34;) f.write(poc) f.write(\u0026#34;\\n```\\n\u0026#34;) if logger: logger(f\u0026#34;Saved Exploit-DB PoC to {poc_filename}\u0026#34;) time.sleep(0.5) descriptions = cve_info.get(\u0026#34;descriptions\u0026#34;, []) description = descriptions[0][\u0026#34;value\u0026#34;] if descriptions else \u0026#34;No description available\u0026#34; md_content = f\u0026#34;# CVE Report: {cve_id}\\n\\n\u0026#34; md_content += f\u0026#34;## NVD Description\\n\\n{description}\\n\\n\u0026#34; is_kev_exploited = cisa_kev_data.get(\u0026#39;is_kev_exploited\u0026#39;, False) md_content += f\u0026#34;**Active Exploitation (CISA KEV):** {\u0026#39;Yes\u0026#39; if is_kev_exploited else \u0026#39;No\u0026#39;}\\n\\n\u0026#34; cvss_metrics_v4 = cve_info.get(\u0026#34;metrics\u0026#34;, {}).get(\u0026#34;cvssMetricV40\u0026#34;, []) cvss_metrics_v3 = cve_info.get(\u0026#34;metrics\u0026#34;, {}).get(\u0026#34;cvssMetricV31\u0026#34;, []) if cvss_metrics_v4: cvss = cvss_metrics_v4[0].get(\u0026#34;cvssData\u0026#34;, {}) md_content += f\u0026#34;**CVSS v4 Base Score:** {cvss.get(\u0026#39;baseScore\u0026#39;, \u0026#39;N/A\u0026#39;)} \\n\u0026#34; md_content += f\u0026#34;**CVSS v4 Base Severity:** {cvss.get(\u0026#39;baseSeverity\u0026#39;, \u0026#39;N/A\u0026#39;)}\\n\\n\u0026#34; elif cvss_metrics_v3: cvss = cvss_metrics_v3[0].get(\u0026#34;cvssData\u0026#34;, {}) md_content += f\u0026#34;**CVSS v3.1 Base Score:** {cvss.get(\u0026#39;baseScore\u0026#39;, \u0026#39;N/A\u0026#39;)} \\n\u0026#34; md_content += f\u0026#34;**CVSS v3.1 Base Severity:** {cvss.get(\u0026#39;baseSeverity\u0026#39;, \u0026#39;N/A\u0026#39;)}\\n\\n\u0026#34; md_content += \u0026#34;---\\n\\n\u0026#34; md_content += \u0026#34;## Full NVD JSON Response\\n\\n\u0026#34; md_content += f\u0026#34;```json\\n{json.dumps(nvd_data, indent=2)}\\n```\\n\\n\u0026#34; md_content += \u0026#34;---\\n\\n\u0026#34; md_content += \u0026#34;## MITRE CVE Information\\n\\n\u0026#34; md_content += f\u0026#34;```json\\n{json.dumps(mitre_cve_data, indent=2)}\\n```\\n\\n\u0026#34; os.makedirs(os.path.join(os.getcwd(), \u0026#39;cve_data\u0026#39;), exist_ok=True) md_filename = os.path.join(os.getcwd(), \u0026#39;cve_data\u0026#39;, f\u0026#34;{cve_id}.md\u0026#34;) with open(md_filename, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as md_file: md_file.write(md_content) if logger: logger(f\u0026#34;Enriched Markdown report saved to {md_filename}\u0026#34;) return True, exploit_db_ids, exploit_db_pocs def build_vector_store(logger=None): try: if logger: logger(\u0026#34;Initializing persistent Chroma client...\u0026#34;) client = chromadb.PersistentClient(path=DB_PATH) embeddings = OllamaEmbeddings(model=\u0026#34;nomic-embed-text\u0026#34;) loader = DirectoryLoader(DATA_DIR, glob=\u0026#34;*.md\u0026#34;) documents = loader.load() if logger: logger(f\u0026#34;Loaded {len(documents)} Markdown documents from {DATA_DIR}\u0026#34;) text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) chunks = text_splitter.split_documents(documents) if logger: logger(f\u0026#34;Split documents into {len(chunks)} chunks\u0026#34;) db = Chroma.from_documents( documents=chunks, embedding=embeddings, client=client, collection_name=COLLECTION_NAME ) if logger: logger(f\u0026#34;Successfully created a vector store with {len(chunks)} chunks.\u0026#34;) return db except Exception as e: if logger: logger(f\u0026#34;Failed to build vector store: {e}\u0026#34;) return None def run_rag_chain(db, cve_id_to_analyze, exploit_db_pocs=None, logger=None): try: if logger: logger(f\u0026#34;Starting RAG chain analysis for {cve_id_to_analyze}...\u0026#34;) llm = OllamaLLM(model=\u0026#34;mistral:instruct\u0026#34;) retriever = db.as_retriever() def escape_braces(text): return text.replace(\u0026#34;{\u0026#34;, \u0026#34;{{\u0026#34;).replace(\u0026#34;}\u0026#34;, \u0026#34;}}\u0026#34;) if exploit_db_pocs and len(exploit_db_pocs) \u0026gt; 0: exploit_pocs_text = \u0026#34;\\n\\n\u0026#34;.join( [f\u0026#34;### Exploit ID: {eid}\\n```text\\n{escape_braces(poc)}\\n```\u0026#34; for eid, poc in exploit_db_pocs] ) else: exploit_pocs_text = \u0026#34;No public exploit proof-of-concept code found.\u0026#34; prompt_template = PromptTemplate( template=f\u0026#34;\u0026#34;\u0026#34; # {cve_id_to_analyze} Exploitability Analysis Report ### Context Based ONLY on the following context, perform a comprehensive exploitability analysis of the provided CVE. All findings and conclusions MUST be supported by this context. Do not use any external knowledge. {{{{context}}}} ### Role You are a Expert Level - Senior Penetration Engineer. Your role is to perform a detailed exploitability analysis and impact assessment of the CVE. You are to produce a report that is technical, exhaustive in its detail, comprehensive, and provides clear, actionable guidance on fixes and mitigations. ### Instructions Analyze the provided CVE. Your task is to generate a detailed, multi-section report in Markdown format. You MUST follow a step-by-step analytical process before writing the report. You MUST provide a clear, concise, and elaborate summary of the CVE and its exploitability status. You MUST include a dedicated section for mitigations and fixes. You MUST adhere to the formatting and structure specified in the \u0026#39;Expectation\u0026#39; section. # New Constraint Added Here You MUST NOT include any conversational introduction, preamble, or any sentences that refer to the report itself. Start directly with the markdown heading for the CVE. ### Steps (Chain of Thought) BEFORE generating your final report, think step-by-step through the following logical process: 1. Review the provided context and identify the core vulnerability type and its root cause. 2. Assess the vulnerability\u0026#39;s potential impact and severity based on the provided CVSS score. 3. Cross-reference the CVE with CISA\u0026#39;s Known Exploited Vulnerabilities (KEV) catalog. If active exploitation is mentioned, make a specific note of this. 4. Search for and evaluate evidence of public exploits or proof-of-concept (PoC) code, including the Exploit DB PoCs provided. Consider the reliability and maturity of these exploits. 5. Synthesize all data points (root cause, CVSS, exploitation evidence, Exploit DB PoCs) to determine the final exploitability verdict: \u0026#34;Critical\u0026#34;, \u0026#34;High\u0026#34;, \u0026#34;Medium\u0026#34;, \u0026#34;Low\u0026#34;, or \u0026#34;Unconfirmed\u0026#34;. 6. Based on your analysis, propose a clear, prioritized set of mitigations, including temporary workarounds and long-term fixes. 7. Formulate a final verdict and a high-level summary that captures the essence of your detailed analysis. ### Expectation Your final output MUST be a well-formatted Markdown document with the following exact structure and headings. Each section must be detailed and comprehensive. ## **Summary** A detailed and elaborate summary of the CVE, its technical nature, and a clear explanation of its exploitability status. Include the range of affected version(s) if there exist a number, list, or range. ## **Verdict** The final verdict on the exploitability status: \u0026#34;Critical\u0026#34;, \u0026#34;High\u0026#34;, \u0026#34;Medium\u0026#34;, \u0026#34;Low\u0026#34;, or \u0026#34;Unconfirmed\u0026#34;. ## **Key Findings** A bulleted list highlighting crucial data points from your analysis: * **Active Exploitation:** State \u0026#34;Yes (from CISA KEV)\u0026#34; or \u0026#34;No (from CISA KEV)\u0026#34; or \u0026#34;Not Available.\u0026#34; * **CVSS Score:** State the full score string (e.g., CVSS 3.1: 8.9) or \u0026#34;Not Available.\u0026#34; * **Public Exploits:** State \u0026#34;Confirmed,\u0026#34; \u0026#34;Unconfirmed,\u0026#34; or \u0026#34;Not Available.\u0026#34; ## Exploit Proof of Concept(s) The following Exploit-DB PoCs are associated with this CVE and MUST be included verbatim in the report: {exploit_pocs_text} ## **Detailed Analysis** A multi-paragraph section that explains the technical details of the vulnerability, how it can be exploited, and the factors that contribute to its exploitability verdict. Include your assessment of the Exploit DB PoCs. ## **Mitigations \u0026amp; Fixes** A comprehensive list of recommended actions to mitigate or fix the vulnerability. This must include: * Immediate, temporary workarounds. * Long-term, permanent fixes (e.g., patching). * Any additional security controls (e.g., WAF rules, network segmentation). ## **Supporting Documents** A bulleted list of the documents and sources used for your analysis. \u0026#34;\u0026#34;\u0026#34;, input_variables=[\u0026#34;context\u0026#34;, \u0026#34;cve_id\u0026#34;], ) rag_chain = ( { \u0026#34;context\u0026#34;: RunnableLambda(lambda x: retriever.invoke(\u0026#34;CVE Report: \u0026#34; + x[\u0026#39;cve_id\u0026#39;])), \u0026#34;cve_id\u0026#34;: RunnablePassthrough() } | prompt_template | llm ) if logger: logger(f\u0026#34;Invoking RAG chain for {cve_id_to_analyze}...\u0026#34;) markdown_report = rag_chain.invoke({\u0026#34;cve_id\u0026#34;: cve_id_to_analyze}) if logger: logger(\u0026#34;RAG chain analysis complete.\u0026#34;) return markdown_report except Exception as e: if logger: logger(f\u0026#34;An error occurred during the RAG process: {e}\u0026#34;) logger(traceback.format_exc()) return \u0026#34;Analysis failed.\u0026#34; def main(): def log(msg): print(msg) parser = argparse.ArgumentParser(description=\u0026#34;Analyze a CVE using RAG.\u0026#34;) parser.add_argument(\u0026#34;--cve\u0026#34;, type=str, required=True, help=\u0026#34;The CVE ID to analyze.\u0026#34;) args = parser.parse_args() cve_to_analyze = args.cve success, exploit_ids, exploit_db_pocs = fetch_and_save_cve(cve_to_analyze, NVD_API_KEY, logger=log) if success: db = build_vector_store(logger=log) if db: run_rag_chain(db, cve_to_analyze, exploit_db_pocs=exploit_db_pocs, logger=log) else: print(\u0026#34;Stopping script due to data retrieval failure.\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() app.py: The Streamlit Frontend This script provides the Orchestration Layer interface for the user. It uses Streamlit to create a simple web application that allows users to input a CVE ID and initiate the full analysis pipeline.\nUser Interface (UI): Provides a clean input field for the CVE ID and a \u0026ldquo;Run Analysis\u0026rdquo; button.\nWorkflow Orchestration: It imports and sequentially calls the core functions from run_system.py: clear_data_directory, fetch_and_save_cve, build_vector_store, and run_rag_chain.\nLogging and Status: It uses a real-time status container to log the progress of each step (e.g., fetching data, building DB, running LLM), giving the user visibility into the backend process.\nResult Presentation: Upon completion, it renders the final Markdown report generated by the RAG chain and includes a \u0026ldquo;Copy Report\u0026rdquo; button.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 # app.py import streamlit as st import time import json import os import sys import re from st_copy_to_clipboard import st_copy_to_clipboard import chromadb from langchain_ollama import OllamaEmbeddings from langchain_community.vectorstores import Chroma from run_system import ( fetch_and_save_cve, build_vector_store, run_rag_chain, clear_data_directory, NVD_API_KEY, DB_PATH, COLLECTION_NAME ) def clean_llm_output(text): return re.sub(r\u0026#39;^`{1,}|`{1,}$\u0026#39;, \u0026#39;\u0026#39;, text.strip()).strip() st.set_page_config( page_title=\u0026#34;Local CVE Exploitability Analyzer\u0026#34;, page_icon=\u0026#34;🕵️‍♂️\u0026#34;, layout=\u0026#34;centered\u0026#34; ) st.title(\u0026#34;🕵️‍♂️ CVE Exploitability Analyzer\u0026#34;) st.write( \u0026#34;Enter a CVE ID to fetch its data, build a knowledge base, and analyze its exploitability using a local RAG system.\u0026#34; ) cve_id_input = st.text_input( \u0026#34;Enter CVE ID:\u0026#34;, placeholder=\u0026#34;CVE-YYYY-NNNN\u0026#34; ) if st.button(\u0026#34;Run Analysis\u0026#34;): if not cve_id_input: st.error(\u0026#34;Please enter a CVE ID.\u0026#34;) else: start_time = time.time() log_lines = [] # fresh log lines for this run # Create logs container BEFORE defining log() logs_display = st.empty() def log(msg): log_lines.append(msg) logs_display.code(\u0026#34;\\n\u0026#34;.join(log_lines), language=\u0026#34;text\u0026#34;) with st.status(f\u0026#34;Analyzing {cve_id_input}...\u0026#34;, expanded=True, state=\u0026#34;running\u0026#34;) as status: status.update(label=f\u0026#34;Clearing old data...\u0026#34;, state=\u0026#34;running\u0026#34;) clear_data_directory(logger=log) status.update(label=f\u0026#34;Fetching data for {cve_id_input}...\u0026#34;, state=\u0026#34;running\u0026#34;) fetch_success, exploit_ids, exploit_db_pocs = fetch_and_save_cve(cve_id_input, NVD_API_KEY, logger=log) if not fetch_success: status.update(label=f\u0026#34;Failed to fetch data for {cve_id_input}.\u0026#34;, state=\u0026#34;error\u0026#34;) st.error(\u0026#34;Failed to fetch CVE data. Please check the CVE ID.\u0026#34;) st.stop() status.update(label=f\u0026#34;Data fetched! Building fresh vector store...\u0026#34;, state=\u0026#34;running\u0026#34;) db = build_vector_store(logger=log) if not db: status.update(label=\u0026#34;Failed to initialize vector store.\u0026#34;, state=\u0026#34;error\u0026#34;) st.error(\u0026#34;Vector store could not be initialized.\u0026#34;) st.stop() status.update(label=f\u0026#34;Database ready! Running LLM analysis on {cve_id_input}...\u0026#34;, state=\u0026#34;running\u0026#34;) report_output = run_rag_chain(db, cve_id_input, exploit_db_pocs=exploit_db_pocs, logger=log) if report_output and \u0026#34;Analysis failed\u0026#34; not in report_output: clean_report = clean_llm_output(report_output) elapsed_time = time.time() - start_time status.update(label=f\u0026#34;Analysis Complete! (Took {elapsed_time:.2f} seconds)\u0026#34;, state=\u0026#34;complete\u0026#34;, expanded=False) st.success(f\u0026#34;Report for {cve_id_input} generated successfully! 🎉\u0026#34;) st.markdown(clean_report) st_copy_to_clipboard(clean_report, \u0026#34;Copy Report\u0026#34;) else: status.update(label=\u0026#34;An error occurred during analysis.\u0026#34;, state=\u0026#34;error\u0026#34;) st.error(\u0026#34;An error occurred during the LLM analysis.\u0026#34;) Program Interaction Flow The two programs work together in a tightly coupled client-server-like model, where app.py acts as the orchestrator and client, and run_system.py provides the underlying analytical services.\nUser Initiates Analysis: The user enters a CVE ID in the app.py Streamlit interface and clicks \u0026ldquo;Run Analysis.\u0026rdquo;\nOrchestration (app.py): app.py begins the process, managing the status display and logs.\nData Cleanup \u0026amp; Retrieval (run_system.py via app.py): app.py calls clear_data_directory to ensure a clean state, followed by fetch_and_save_cve to gather data from NVD, MITRE, CISA, and Exploit-DB, storing it in the cve_data directory.\nKnowledge Base Build (run_system.py via app.py): app.py calls build_vector_store, which reads the new Markdown files, chunks them, embeds them, and stores the vectors in the cve_database (ChromaDB).\nLLM Analysis (run_system.py via app.py): app.py calls the core RAG function, run_rag_chain. This function uses the new vector store for context, queries the Ollama LLM (mistral:instruct), and returns the final, structured Markdown report.\nReport Display (app.py): app.py receives the Markdown report, cleans it, and renders it directly in the Streamlit application for the user.\nResults \u0026amp; Outputs Template Terminal/Streamlit Log Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Clearing contents of ./cve_data... Deleting database directory ./cve_database... Successfully deleted ./cve_database Successfully retrieved NVD data for CVE-YYYY-NNNN. Successfully retrieved MITRE CVE data for CVE-YYYY-NNNN. Successfully retrieved and searched CISA KEV data. Found Exploit-DB IDs [\u0026#39;XXXXX\u0026#39;, \u0026#39;YYYYY\u0026#39;] for CVE CVE-YYYY-NNNN Successfully fetched Exploit-DB PoC for ID XXXXX Saved Exploit-DB PoC to ./cve_data/CVE-YYYY-NNNN_exploit_XXXXX.md Successfully fetched Exploit-DB PoC for ID YYYYY Saved Exploit-DB PoC to ./cve_data/CVE-YYYY-NNNN_exploit_YYYYY.md Enriched Markdown report saved to /path/to/cve-explpoit-proj/cve_data/CVE-YYYY-NNNN.md Initializing persistent Chroma client... Loaded 3 Markdown documents from ./cve_data Split documents into 12 chunks Successfully created a vector store with 12 chunks. Starting RAG chain analysis for CVE-YYYY-NNNN... Invoking RAG chain for CVE-YYYY-NNNN... RAG chain analysis complete. Real Terminal/Streamlit Log Output ","date":"2025-10-09T14:56:21-07:00","image":"https://crxso.github.io/p/local-cve-exploitability-analyzer/rivendell_hu_7c6fc60aee76a992.jpg","permalink":"https://crxso.github.io/p/local-cve-exploitability-analyzer/","title":"Local CVE Exploitability Analyzer"},{"content":" Version Updated on Updated by v1.0.0 10/03/2025 @crxso RAG Structure Retrieval-Augmented Generation (RAG) is a technique that uses Large Language Models (LLMs) with external, proprietary knowledge to improve accuracy and reduce \u0026ldquo;hallucination\u0026rdquo;. The success of any RAG system relies entirely on its ability to quickly and accurately retrieve relevant context from a knowledge base.\nHallucination is a phenomenon where the LLM generates a response that is plausible-sounding and fluent but is factually incorrect, nonsensical, or unfaithful to the source information. This analysis focuses on the preferred, structured approach for RAG, which utilizes a dedicated vector database (like ChromaDB) and a specialized embedding model (i.e., Nomic Embed), as opposed to simple file storage methods like CSVs.\nWorkflow Diagram RAG Workflow Diagram Explanation The RAG workflow is divided into two distinct, interconnected phases: the Indexing Pipeline (done offline or periodically) and the Retrieval \u0026amp; Generation Pipeline (done live every time a user asks a question).\nPhase 1: Indexing Pipeline (Pre-Processing) This phase builds the searchable knowledge base, which is the alternative to using a simple CSV file.\nRaw Documents: Your source data, such as PDFs, text files, or data extracted from CSVs.\nRole of Specified Tool: This is the proprietary data that the Large Language Model (LLM) was not trained on. Chunking: The process of splitting large documents into smaller, manageable text sections (chunks).\nPurpose: LLMs and vector search operate better on smaller, contextually coherent blocks of text, as very long documents exceed the model\u0026rsquo;s token limits and introduce irrelevant noise. Nomic Embed (Vectorization): Each text chunk is passed through the Nomic Embed model, which converts the text\u0026rsquo;s semantic meaning into a dense numerical array (a vector).\nTool: The Nomic Embed model is the Embedding Model. It creates high-quality vectors that enable semantic search. ChromaDB (Vector Store): The resulting vector and its corresponding original text chunk are stored here.\nTool: ChromaDB is the Vector Store. It is optimized to index, store, and manage these vectors, building a fast index that makes the vectors easily searchable by mathematical similarity. Vectors: The resulting high-dimensional numerical data points ready for search.\nRole of Specified Tool: This is the final, structured representation of your knowledge base, which is infinitely more useful than raw text in a CSV for RAG. Phase 2: Retrieval Pipeline (Query Time) This phase happens in real-time and is the core of the RAG process.\nUser Query: The natural language question asked by the end-user (e.g., \u0026ldquo;What is the policy on annual leave?\u0026rdquo;).\nNomic Embed (Vectorization): The user\u0026rsquo;s query is passed through the exact same Nomic Embed model used in the Indexing Phase. This ensures the query is mapped to the same semantic vector space as the stored documents, allowing for accurate comparison.\nChromaDB (Vector Store) / Search/KNN: The resulting Query Vector is sent to ChromaDB, which performs a K-Nearest Neighbors (KNN) search to find the vectors that are mathematically closest to the Query Vector.\nRetrieval / Top N Context Chunks: The original text chunks associated with those closest vectors are retrieved (e.g., the top 3 paragraphs about the \u0026ldquo;annual leave policy\u0026rdquo;). This is the relevant, factually grounded context pulled from your knowledge base.\nLLM Prompt (Augmented Prompt): The retrieved text chunks are combined with the original User Query into a single, cohesive message template.\nTemplate Example: \u0026ldquo;Use the following context to answer the question: [Top N Context Chunks]. Question: [User Query].\u0026rdquo;* Final Answer (Generation): The complete augmented prompt is passed to the LLM (the Generative Model). The LLM uses the provided facts (the context) to formulate a coherent, factually grounded response, minimizing \u0026ldquo;hallucination\u0026rdquo; by relying on the context provided by ChromaDB.\nBenefits to Utilizing Vector Databases The Indexing Problem: Vector Databases vs. CSV The fundamental difference between a CSV file and a vector database for RAG lies in the type of search they enable: Keyword Search versus Semantic Search. Using a vector store transforms your knowledge base from a simple storage file into an intelligent, searchable index capable of understanding intent.\nA vector database is a specialized type of database designed to store, manage, and retrieve vector embeddings; high-dimensional numerical representations of unstructured data like text, images, or audio.\nIt enables highly efficient and fast semantic search by measuring the distance (or similarity) between two vectors, allowing applications to retrieve data based on meaning or context rather than exact keyword matches.\nUsing a vector store like ChromaDB transforms your knowledge base from a simple storage file into an intelligent, searchable index capable of understanding intent, which is beneficial for RAG outputs.\nPython Example This python code sets up a Retrieval-Augmented Generation (RAG) system by using the Nomic Embed model to convert data from a local CSV file into numerical vectors, which are then stored in a ChromaDB vector store. The code initializes a PandasAI SmartDataframe with an Ollama LLM and the ChromaDB vector store, allowing the user to query the DataFrame and retrieve contextually grounded answers from the indexed CSV data. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python3 import pandas as pd from pandasai import SmartDataframe from langchain_ollama import OllamaLLM, OllamaEmbeddings from langchain_community.vectorstores import Chroma from langchain.schema import Document # 1. CONFIGURATION LLM_MODEL = \u0026#34;qwen2.5-coder:7b\u0026#34; EMBEDDING_MODEL = \u0026#34;nomic-embed-text\u0026#34; CSV_PATH = \u0026#34;CSV_PATH has been removed for security/privacy\u0026#34; CHROMA_PATH = \u0026#34;./chroma_db\u0026#34; # 2. INITIALIZE COMPONENTS # Ollama models are assumed to be running via \u0026#39;ollama serve\u0026#39; ollama_llm = OllamaLLM(model=LLM_MODEL) ollama_embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL) # 3. LOAD \u0026amp; PREPARE DATA # NOTE: Assuming \u0026#39;df\u0026#39; is loaded from CSV_PATH here for demonstration df = pd.read_csv(\u0026#34;your_data.csv\u0026#34;) # Convert DataFrame rows into LangChain Documents documents = [] for index, row in df.iterrows(): # Combine all values into a single string for embedding content = \u0026#34;, \u0026#34;.join([f\u0026#34;{col}: {val}\u0026#34; for col, val in row.items()]) # Optional: Add metadata metadata = {\u0026#34;row_index\u0026#34;: index} documents.append(Document(page_content=content, metadata=metadata)) # 4. CREATE/LOAD CHROMA VECTOR STORE print(\u0026#34;Indexing data into ChromaDB... (This may take a moment the first time)\u0026#34;) vectorstore = Chroma.from_documents( documents=documents, embedding=ollama_embeddings, persist_directory=CHROMA_PATH ) print(\u0026#34;ChromaDB Indexing Complete.\u0026#34;) # 5. INTERACT WITH SMARTDATAFRAME USING THE VECTOR STORE # The \u0026#39;vector_store\u0026#39; config enables RAG for complex, non-data-manipulation queries. sdf = SmartDataframe( df, config={ \u0026#34;llm\u0026#34;: ollama_llm, \u0026#34;vector_store\u0026#34;: vectorstore, # Pass the initialized vector store here \u0026#34;enable_code_execution\u0026#34;: True # Essential for PandasAI to run generated code } ) # Example 1: A general, non-data query (uses Vector Store/RAG) rag_query = \u0026#34;Summarize the types of service images mentioned in the dataset.\u0026#34; response_rag = sdf.chat(rag_query) print(f\u0026#34;\\n--- RAG Query Response (Vector Store):\\n{response_rag}\u0026#34;) # Example 2: A data analysis query (uses DataFrame/Code Generation) analysis_query = \u0026#34;What is the average value of the \u0026#39;impact_score\u0026#39; column?\u0026#34; response_analysis = sdf.chat(analysis_query) print(f\u0026#34;\\n--- Analysis Query Response (DataFrame):\\n{response_analysis}\u0026#34;) # The original query # Since the query contains the specific text you indexed, the vector store can retrieve the document containing that text and the LLM can extract the version. vector_query = \u0026#34;what is the version of this service image: [service_image]\u0026#34; response_vector = sdf.chat(vector_query) print(f\u0026#34;\\n--- Specific Vector Query Response:\\n{response_vector}\u0026#34;) Comparison Table Feature CSV/Flat File Storage Vector Database (ChromaDB) Indexing Method Keyword-based (e.g., full-text search) or simple relational index. High-dimensional vector indexing (e.g., HNSW) for fast Nearest Neighbor search. Search Type Keyword Search: Requires exact word matches or close synonyms. Semantic Search: Finds information based on meaning and context, even if the exact words are not present. Scalability Poor. Search time increases linearly with data size. Excellent. Optimized for querying billions of vectors efficiently and at low latency. Relevance Low precision. Cannot capture nuance, complex relationships, or abstract concepts. High precision. Captures semantic distance, ensuring the retrieved context is genuinely relevant to the query\u0026rsquo;s intent. The Role of Embedding Models: Nomic Embed An embedding model\u0026rsquo;s primary function is to transform raw text (your documents and the user\u0026rsquo;s query) into numerical representations called vectors. Nomic Embed provides the translation layer that makes semantic search possible.\n1 2 3 4 # Command used to display currently downloaded models Ollama list nomic-embed-text:latest 0a10XXXXXXXX 274 MB 7 days ago High Fidelity: Nomic models are designed to be competitive with and often outperform existing proprietary models, capturing subtle semantic relationships and context.\nLong Context Window: They feature a long context length, which is best for RAG. A longer context window allows the model to embed larger chunks of text accurately, ensuring that vectors retain the full context of lengthy documents.\nStructured Advantage: Utilizing Nomic Embed guarantees that every piece of data indexed is represented in a uniform, high-dimensional space, which is what the vector database (ChromaDB) is optimized to search across. Without a powerful embedding model, the quality of the RAG output suffers significantly.\n","date":"2025-10-03T21:41:29-07:00","image":"https://crxso.github.io/p/approach-to-retrieval-augmented-generation-rag/balrog_hu_93fc4f2866dc2a75.jpg","permalink":"https://crxso.github.io/p/approach-to-retrieval-augmented-generation-rag/","title":"Approach to Retrieval-Augmented Generation (RAG)"},{"content":" Version Updated on Updated by v1.0.0 10/01/2025 @crxso Install Ollama and Dependencies This guide will walk you through installing Ollama to run large language models (LLMs) locally and then setting up and running localGPT, a system for local RAG (Retrieval-Augmented Generation).\nEnvironment Setup It\u0026rsquo;s highly recommended to use a Python virtual environment to isolate project dependencies.\n1 2 3 4 5 6 7 # Create a new virtual environment (e.g., named \u0026#39;local-ai-env\u0026#39;) python3 -m venv local-ai-env # Activate the virtual environment source local-ai-env/bin/activate # Your terminal prompt should now show the environment name (e.g., (local-ai-env)) Install Homebrew (Without Admin Privileges) If you do not have sudo or admin privileges, you can install Homebrew by cloning the repository and adding it to your PATH.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Clone the Homebrew repository into the \u0026#39;brew\u0026#39; directory in your home folder (~/) git clone [https://github.com/Homebrew/brew.git](https://github.com/Homebrew/brew.git) ~/brew # Add Homebrew\u0026#39;s binaries to your PATH for the current session # This path matches your verified installation location. export PATH=\u0026#34;$HOME/brew/bin:$PATH\u0026#34; # Add this line to your shell profile file (e.g., ~/.zshrc or ~/.bash_profile) # for persistent access in new terminals. # For example, for zsh: echo \u0026#39;export PATH=\u0026#34;$HOME/brew/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # Verify the installation which brew brew --prefix # Expected output similar to: # /Users/\u0026lt;user\u0026gt;/brew/bin/brew # /Users/\u0026lt;user\u0026gt;/brew Install Ollama and System Dependencies Use Homebrew to install Ollama and the necessary C library libmagic.\n1 2 3 4 5 # Install Ollama brew install ollama # Install System Dependencies: libmagic is required by the framework brew install libmagic Fix Library Linking (macOS Specific) On macOS, you may need to set the DYLD\\_LIBRARY\\_PATH environment variable so Python can find the libmagic installation. The path now correctly reflects the ~/brew structure.\n1 2 3 4 5 6 # Set DYLD_LIBRARY_PATH for the current session export DYLD_LIBRARY_PATH=\u0026#34;$HOME/brew/lib:$DYLD_LIBRARY_PATH\u0026#34; # Add this line to your shell profile for persistence. # For example, for zsh: # echo \u0026#39;export DYLD_LIBRARY_PATH=\u0026#34;$HOME/brew/lib:$DYLD_LIBRARY_PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc Run Ollama Server and Download LLM The Ollama server must be running to interact with models, and you need to download a model for localGPT to use.\nStart the Ollama Server The server must be running in the background. Open a new terminal window and run the following command.\nNote: This terminal must remain open. 1 ollama serve Download LLM Download a code-focused model, like codellama:13b-instruct, which offers a good balance of capability and performance for local machines.\n1 ollama pull codellama:13b-instruct You can verify the download by running:\n1 ollama list Setup and Run localGPT localGPT is a project that uses Ollama and a vector database for local RAG functionality.\nClone and Prepare localGPT In your original terminal window (the one with the activated virtual environment), clone the localGPT repository and install its dependencies.\n1 2 3 4 5 6 7 8 9 10 # Clone the repository git clone [https://github.com/PromtEngineer/localGPT.git](https://github.com/PromtEngineer/localGPT.git) cd localGPT # Install Python dependencies pip install -r requirements.txt # Key dependencies include: torch, transformers, lancedb, sentence_transformers, docling. # Install Node.js dependencies (for the web interface) npm install Run localGPT You already have the Ollama server running in a separate terminal. Now, start the localGPT application.\n1 2 # Start the localGPT system python run_system.py Access the Application Once the script is running, the localGPT web application will be accessible.\n1 2 # Access the application open http://localhost:3000 You can now use your local LLM with the localGPT interface! 🎉\nFinal Cleanup When you are finished, you can close the terminal running ollama serve to stop the server. To exit the Python virtual environment in your other terminal:\n1 deactivate ","date":"2025-10-01T20:42:52-07:00","image":"https://crxso.github.io/p/local-ai-setup/ollama_hu_ae966ac4827a4c1c.png","permalink":"https://crxso.github.io/p/local-ai-setup/","title":"Local AI Setup"}]